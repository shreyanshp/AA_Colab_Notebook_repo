{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-Transfer-Learning-TensorflowJS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyanshp/AA_Colab_Notebook_repo/blob/master/Keras_Transfer_Learning_TensorflowJS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2RAzNCCnBpHZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a8ababc-330e-4441-9868-3bf27da1b5f8"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD, Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QnDCGlhVB5Yv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fa41fbac-940b-4352-a34a-0250ffa0b97b"
      },
      "cell_type": "code",
      "source": [
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape=(HEIGHT, WIDTH, 3))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nCl6FeoxGLMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "02ee1861-6787-4235-9052-bc20efdf7a58"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'food_dataset/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YIWl16SDCDBR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e47f45ff-1a06-424f-949c-4d0e5e6549a0"
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = base_dir\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH), \n",
        "                                                    batch_size=BATCH_SIZE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NnkdriJPCaY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b843e880-f297-4712-b7d7-35f4aeab4e42"
      },
      "cell_type": "code",
      "source": [
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    for fc in fc_layers:\n",
        "        # New FC layer, random init\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # New softmax layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model\n",
        "\n",
        "class_list = [\"pizza\", \"burger\", \"taco\"]\n",
        "FC_LAYERS = [1024, 1024]\n",
        "dropout = 0.5\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=len(class_list))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hax_3ckACmo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "59c8b3f8-dc30-44a4-bd25-2e48d0add217"
      },
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 8\n",
        "num_train_images = 10000\n",
        "\n",
        "adam = Adam(lr=0.00001)\n",
        "finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True)\n",
        "\n",
        "!rm -rf ./mymobilenet* ./model.h5\n",
        "finetune_model.save('./model.h5')\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "1250/1250 [==============================] - 160s 128ms/step - loss: 0.0511 - acc: 0.9828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6OCCO417RLVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "6e74937f-5274-4250-f400-ce80939a8c3c"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/79/29/35e1aa467436ff46b98df65a08c49faaedb3429e1c512d1d90fe308040a0/tensorflowjs-1.0.1-py3-none-any.whl\n",
            "Collecting tf-nightly-2.0-preview>=2.0.0.dev20190304 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/92/7ae5e1499112fcaca72d8f6df47ce4206143c2dbd7c7cd1de29305ade060/tf_nightly_2.0_preview-2.0.0.dev20190405-cp36-cp36m-manylinux1_x86_64.whl (96.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 96.1MB 437kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.4)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting tensorflow-hub==0.3.0 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/f0/3a3ced04c8359e562f1b91918d9bde797c8a916fcfeddc8dc5d673d1be20/tensorflow_hub-0.3.0-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 23.1MB/s \n",
            "\u001b[?25hCollecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.33.1)\n",
            "Collecting google-pasta>=0.1.2 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 23.0MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/17/a3d05a0664c11703259aa79d2b58b871b3bb1fff24153f75db04540489db/tb_nightly-1.14.0a20190319-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.0.9)\n",
            "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/d8/563f4a419f9db1d7c5b947fbc22d5d51bc2d11a8a1e194a5355858fa8cbf/tensorflow_estimator_2.0_preview-1.14.0.dev2019040900-py2.py3-none-any.whl (356kB)\n",
            "\u001b[K    100% |████████████████████████████████| 358kB 19.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (40.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (3.1)\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-pasta, numpy, tb-nightly, tensorflow-estimator-2.0-preview, tf-nightly-2.0-preview, tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: tensorflow-hub 0.4.0\n",
            "    Uninstalling tensorflow-hub-0.4.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.4.0\n",
            "Successfully installed google-pasta-0.1.5 numpy-1.15.1 tb-nightly-1.14.0a20190319 tensorflow-estimator-2.0-preview-1.14.0.dev2019040900 tensorflow-hub-0.3.0 tensorflowjs-1.0.1 tf-nightly-2.0-preview-2.0.0.dev20190405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "heZcNQ8VMeEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        },
        "outputId": "c83d9904-7a6d-48f8-cd58-0a1f15a33e28"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!tensorflowjs_converter --input_format=keras ./model.h5 ./mymobilenet\n",
        "!zip -r ./mymobilenet.zip ./mymobilenet \n",
        "files.download( \"./mymobilenet.zip\" )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: mymobilenet/ (stored 0%)\n",
            "  adding: mymobilenet/group1-shard61of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard27of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard13of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard20of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard35of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard51of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard11of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard18of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard23of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard31of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/model.json (deflated 95%)\n",
            "  adding: mymobilenet/group1-shard38of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard34of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard2of65.bin (deflated 7%)\n",
            "  adding: mymobilenet/group1-shard62of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard47of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard14of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard54of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard40of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard41of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard57of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard65of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard50of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard28of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard19of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard58of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard30of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard60of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard12of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard49of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard26of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard10of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard44of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard1of65.bin (deflated 7%)\n",
            "  adding: mymobilenet/group1-shard46of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard4of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard48of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard53of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard22of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard45of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard64of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard9of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard29of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard3of65.bin (deflated 7%)\n",
            "  adding: mymobilenet/group1-shard55of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard6of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard33of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard5of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard39of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard63of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard52of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard32of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard15of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard43of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard8of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard16of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard42of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard24of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard17of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard25of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard7of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard56of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard21of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard59of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard37of65.bin (deflated 8%)\n",
            "  adding: mymobilenet/group1-shard36of65.bin (deflated 8%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}